{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f16a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "    # This code calculates the permafrost sensitivity estimated from Chadburn et al.(2017)\n",
    "    # 1. Calculate average air temperature for each grid during 1982-2014 (ERA5-Land data)—— t2m_basemean\n",
    "    # 2. Calculate the temperature change from 1986-2005 to 1982-2014 (HadCRUT5 data)\n",
    "    # 3. Calculate temperature for each grid under three warming thresholds, using t2m_basemean and amplification factors\n",
    "    # 4. Calculate permafrost probability corresponding to air temperature based on the formula\n",
    "    # 5. Calculate permafrost sensitivity based on changes in permafrost area\n",
    "    # 6. The sensitivity is plot in Figure 3.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d47ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read NetCDF file\n",
    "file_path = \"/home/jidy/Data/ERA5-Land/ERA5-Land_2m-temperature_monthly_NH_1950-2022.nc\"\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# 2. Extract variables and time information\n",
    "t2m = ds[\"t2m\"]\n",
    "time = ds[\"time\"]\n",
    "\n",
    "# 3. Automatically parse time (priority: read from attributes)\n",
    "time_units = ds[\"time\"].attrs.get(\"units\", None)\n",
    "if time_units:\n",
    "    # If time units exist, attempt to parse\n",
    "    time_values = xr.cftime_range(start=\"1950-01\", freq=\"MS\", periods=len(time))\n",
    "else:\n",
    "    # Manually set time range\n",
    "    time_values = xr.cftime_range(start=\"1950-01\", periods=len(time), freq=\"MS\")\n",
    "\n",
    "t2m = t2m.assign_coords(time=(\"time\", time_values))\n",
    "\n",
    "# 4. Filter time range for 1982-2014\n",
    "t2m_sel = t2m.sel(time=slice(\"1982-01\", \"2014-12\"))\n",
    "\n",
    "# 5. Replace missing values\n",
    "fill_value = -32767\n",
    "t2m = t2m.where(t2m != fill_value)\n",
    "\n",
    "# 6. Decode scale_factor and add_offset\n",
    "scale_factor = 0.00145277162700054\n",
    "add_offset = 267.639219598073\n",
    "t2m = t2m * scale_factor + add_offset\n",
    "\n",
    "# 7. Calculate average temperature for each grid during 1982-2014\n",
    "t2m_basemean = t2m_sel.mean(dim=\"time\", skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982-2014 annual average temperature anomaly: 0.38363636\n",
      "1986-2005 annual average temperature anomaly: 0.34915000\n",
      "Compared to 1986-2005, the global average temperature in 1982-2014 increased by: 0.03448636\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define two lists for the two time periods, storing annual average temperature anomalies for each year\n",
    "    anomalies_1982_2014 = []\n",
    "    anomalies_1986_2005 = []\n",
    "\n",
    "    filename = \"/home/wangjx/Data/HadCRUT5.0Analysis_gl.txt\" \n",
    "\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found, please check if the path is correct.\")\n",
    "        return\n",
    "\n",
    "    # Each year in the file has two lines of data, so the step size is 2\n",
    "    for i in range(0, len(lines), 2):\n",
    "        # First line: temperature anomaly data\n",
    "        line_temp = lines[i].strip()\n",
    "        if not line_temp:\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        # Split this line into several strings by whitespace characters\n",
    "        tokens = line_temp.split()\n",
    "        if len(tokens) < 14:\n",
    "            # Incomplete data, skip\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            year = int(tokens[0])\n",
    "            # The annual average anomaly value is the last number in the line (total 13 numbers, with the first being the year, the next 12 being monthly data, and no annual value in between)\n",
    "            # According to the file format description: format(i5,13f7.3), the actual data arrangement is: year, 12 months of data, annual data\n",
    "            # The tokens list should have 1 + 13 = 14 elements, where tokens[-1] is the annual value.\n",
    "            annual_anomaly = float(tokens[-1])\n",
    "        except ValueError:\n",
    "            # Data conversion failed, skip this line\n",
    "            continue\n",
    "\n",
    "        # If the year is between 1982 and 2014, store it in the corresponding list\n",
    "        if 1982 <= year <= 2014:\n",
    "            anomalies_1982_2014.append(annual_anomaly)\n",
    "        # If the year is between 1986 and 2005, store it in the corresponding list\n",
    "        if 1986 <= year <= 2005:\n",
    "            anomalies_1986_2005.append(annual_anomaly)\n",
    "\n",
    "    # Check if data was found\n",
    "    if not anomalies_1982_2014:\n",
    "        print(\"No data found for the 1982-2014 period.\")\n",
    "        return\n",
    "    if not anomalies_1986_2005:\n",
    "        print(\"No data found for the 1986-2005 period.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the average temperature anomalies for the two time periods\n",
    "    avg_1982_2014 = sum(anomalies_1982_2014) / len(anomalies_1982_2014)\n",
    "    avg_1986_2005 = sum(anomalies_1986_2005) / len(anomalies_1986_2005)\n",
    "\n",
    "    # Calculate the temperature difference, representing the temperature change from 1986-2005 to 1982-2014\n",
    "    delta = avg_1982_2014 - avg_1986_2005\n",
    "\n",
    "    # Output results\n",
    "    print(\"1982-2014 annual average temperature anomaly: {:.8f}\".format(avg_1982_2014))\n",
    "    print(\"1986-2005 annual average temperature anomaly: {:.8f}\".format(avg_1986_2005))\n",
    "    print(\"Compared to 1986-2005, the global average temperature in 1982-2014 increased by: {:.8f}\".format(delta))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = [1.5, 2, 3]\n",
    "lat = ds[\"latitude\"].data\n",
    "lon = ds[\"longitude\"].data\n",
    "# Calculate average temperature relative to pre-industrial period\n",
    "t2m_basemean = t2m_basemean - 273.15\n",
    "for i in range(len(degree)):\n",
    "    # Create an empty array with the same shape as taspre_mean\n",
    "    tas_future = np.zeros_like(t2m_basemean)\n",
    "    for j in range(len(lat)):\n",
    "        if lat[j] <= 50:\n",
    "            Amplification_factor = 2.319\n",
    "        elif lat[j] <= 55:\n",
    "            Amplification_factor = 2.484\n",
    "        elif lat[j] <= 60:\n",
    "            Amplification_factor = 2.600\n",
    "        elif lat[j] <= 65:\n",
    "            Amplification_factor = 2.482\n",
    "        elif lat[j] <= 70:\n",
    "            Amplification_factor = 2.474\n",
    "        elif lat[j] <= 75:\n",
    "            Amplification_factor = 2.552\n",
    "        elif lat[j] <= 80:\n",
    "            Amplification_factor = 2.254\n",
    "        elif lat[j] <= 85:\n",
    "            Amplification_factor = 1.797\n",
    "        else:\n",
    "            continue\n",
    "        tas_future[j, :] = t2m_basemean[j, :] + (degree[i] - (0.61 + 0.03448636)) * Amplification_factor\n",
    "\n",
    "    f = xr.Dataset(\n",
    "        {'tas_future': (['lat', 'lon'], tas_future)},\n",
    "        coords={'lat': lat, 'lon': lon}\n",
    "    )\n",
    "    # Add some metadata\n",
    "    f.attrs['description'] = 't2m_basemean[j,:] + (degree[i] - (0.61 + 0.03448636)) * Amplification_factor'\n",
    "    # Save as NetCDF file\n",
    "    output_file = '../Data/Tas_used_in_Chadburn_approach/' + str(degree[i]) + '_tas_lat_lon.nc'\n",
    "    f.to_netcdf(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate historical period average temperature (lat, lon)\n",
    "# 1. Read NetCDF file\n",
    "file_path = \"/home/jidy/Data/ERA5-Land/ERA5-Land_2m-temperature_monthly_NH_1950-2022.nc\"\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# 2. Extract variables and time information\n",
    "t2m = ds[\"t2m\"]\n",
    "time = ds[\"time\"]\n",
    "\n",
    "# 3. Automatically parse time (priority: read from attributes)\n",
    "time_units = ds[\"time\"].attrs.get(\"units\", None)\n",
    "if time_units:\n",
    "    # If time units exist, attempt to parse\n",
    "    time_values = xr.cftime_range(start=\"1950-01\", freq=\"MS\", periods=len(time))\n",
    "else:\n",
    "    # Manually set time range\n",
    "    time_values = xr.cftime_range(start=\"1950-01\", periods=len(time), freq=\"MS\")\n",
    "\n",
    "t2m = t2m.assign_coords(time=(\"time\", time_values))\n",
    "\n",
    "# 4. Filter time range for 1982-2014\n",
    "t2m_sel = t2m.sel(time=slice(\"1982-01\", \"2014-12\"))\n",
    "\n",
    "# 5. Replace missing values\n",
    "fill_value = -32767\n",
    "t2m = t2m.where(t2m != fill_value)\n",
    "\n",
    "# 6. Decode scale_factor and add_offset\n",
    "scale_factor = 0.00145277162700054\n",
    "add_offset = 267.639219598073\n",
    "t2m = t2m * scale_factor + add_offset\n",
    "\n",
    "# 7. Calculate average temperature for each grid during 1986-2005\n",
    "t2m_basemean = t2m_sel.mean(dim=\"time\", skipna=True)\n",
    "\n",
    "# 8. Check results\n",
    "print(t2m_basemean)\n",
    "\n",
    "# 9. Save results as NetCDF file\n",
    "lat = ds[\"latitude\"].data\n",
    "lon = ds[\"longitude\"].data\n",
    "f = xr.Dataset(\n",
    "    {'tas_history': (['lat', 'lon'], t2m_basemean.data-273.15)},\n",
    "    coords={'lat': lat, 'lon': lon}\n",
    ")\n",
    "# Add some metadata\n",
    "f.attrs['description'] = '1982-2014_mean'\n",
    "# Save as NetCDF file\n",
    "output_file = '../Data/Chadburn_result/ERA5L_equilibrium_future_tas_lat_lon/his_tas_lat_lon.nc'\n",
    "f.to_netcdf(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2dde68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../Data/Tas_used_in_Chadburn_approach/his_tas_lat_lon.nc\n",
      "TAS max: 34.427215576171875, TAS min: -28.490447998046875\n",
      "P max: 1.0, P min: 0.0\n",
      "Permafrost area: 17.44524262936749 million km²\n",
      "Processing: ../Data/Tas_used_in_Chadburn_approach/1.5_tas_lat_lon.nc\n",
      "TAS max: 36.41115188598633, TAS min: -26.56212043762207\n",
      "P max: 1.0, P min: 0.0\n",
      "Permafrost area: 13.843132223792479 million km²\n",
      "Processing: ../Data/Tas_used_in_Chadburn_approach/2_tas_lat_lon.nc\n",
      "TAS max: 37.57065200805664, TAS min: -25.43511962890625\n",
      "P max: 0.9999999999999998, P min: 0.0\n",
      "Permafrost area: 11.86568500876187 million km²\n",
      "Processing: ../Data/Tas_used_in_Chadburn_approach/3_tas_lat_lon.nc\n",
      "TAS max: 39.889652252197266, TAS min: -23.181119918823242\n",
      "P max: 0.9999999999998052, P min: 0.0\n",
      "Permafrost area: 8.249233787163924 million km²\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>his_pfarea</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.462535</td>\n",
       "      <td>6.604832</td>\n",
       "      <td>5.559088</td>\n",
       "      <td>3.557557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   his_pfarea       1.5         2         3\n",
       "0    8.462535  6.604832  5.559088  3.557557"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define constants\n",
    "PI = np.pi\n",
    "RADIUS = 6372 * 1e3  # Earth radius (m)\n",
    "GRID_RES = 0.1  # Grid resolution (°)\n",
    "MEAN = -4.38  # Mean value\n",
    "SD = 2.59  # Standard deviation\n",
    "FILL_VALUE = np.nan\n",
    "pf = pd.DataFrame(columns=['his_pfarea', '1.5', '2', '3'])\n",
    "# Read folder path for future temperature data\n",
    "input_dir = \"../Data/Tas_used_in_Chadburn_approach/\"\n",
    "\n",
    "# File name matching pattern\n",
    "degree_list = [\"his\", \"1.5\", \"2\", \"3\"]  # List of degrees for looping\n",
    "\n",
    "# Iterate through each file\n",
    "for k in range(len(degree_list)):\n",
    "    \n",
    "    file_path = input_dir + degree_list[k] + '_tas_lat_lon.nc'\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    # Read data\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    lat = ds[\"lat\"].data\n",
    "    lon = ds[\"lon\"].data\n",
    "    if k == 0:\n",
    "        tas = ds[\"tas_history\"].data  # Replace with tas_future or tas_history\n",
    "    else:\n",
    "        tas = ds[\"tas_future\"].data\n",
    "        degree = degree_list[k]\n",
    "    # Handle missing values\n",
    "    # tas = np.where(np.isnan(tas), 0.0, tas)  # Replace NaN with 0\n",
    "    print(f\"TAS max: {np.nanmax(tas)}, TAS min: {np.nanmin(tas)}\")\n",
    "    \n",
    "    # Calculate probability distribution P\n",
    "    mean_arr = np.full_like(tas, MEAN)\n",
    "    sd_arr = np.full_like(tas, SD)\n",
    "    P = 1 - norm.cdf(tas, loc=mean_arr, scale=sd_arr)\n",
    "    P = np.where(np.isnan(P), FILL_VALUE, P)  # Fill missing values\n",
    "    print(f\"P max: {np.nanmax(P)}, P min: {np.nanmin(P)}\")\n",
    "    # Calculate area weights\n",
    "    nlat, nlon = len(lat), len(lon)\n",
    "    areacella = np.zeros((nlat, nlon))\n",
    "    for i in range(nlat):\n",
    "        for j in range(nlon):\n",
    "            areacella[i, j] = abs(\n",
    "                RADIUS**2 * (GRID_RES / 180) * PI * (\n",
    "                    np.sin((lat[i] + GRID_RES / 2) / 180 * PI) -\n",
    "                    np.sin((lat[i] - GRID_RES / 2) / 180 * PI)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Masked P\n",
    "    P_masked = P * areacella\n",
    "    P_masked = np.where(np.isnan(P_masked), 0.0, P_masked)  # Handle missing values again\n",
    "\n",
    "    # Calculate permafrost area\n",
    "    pf_area = np.sum(P_masked) / 1e12  # Convert to million square kilometers\n",
    "    if k == 0:\n",
    "        pf.loc[0] = np.sum(P_masked[:451, 1801:]) / 1e12 + np.sum(P_masked[:451, :101]) / 1e12\n",
    "    else:\n",
    "        pf[str(degree)].loc[0] = np.sum(P_masked[:451, 1801:]) / 1e12 + np.sum(P_masked[:451, :101]) / 1e12\n",
    "    print(f\"Permafrost area: {pf_area} million km²\")\n",
    "    k = k + 1\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c781ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.659536</td>\n",
       "      <td>-25.311016</td>\n",
       "      <td>-24.606562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1.5          2          3\n",
       "0 -25.659536 -25.311016 -24.606562"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the permafrost sensitivity to global warming\n",
    "pf_sen_percent = pd.DataFrame(columns = ['1.5','2','3'])\n",
    "pf_sen_percent.loc[0] = (pf['1.5'].loc[0] - pf['his_pfarea'].loc[0]) / (1.5-(0.61+0.03448636))/pf['his_pfarea'].loc[0]*100\n",
    "pf_sen_percent['2'].loc[0] = (pf['2'].loc[0] - pf['his_pfarea'].loc[0]) / (2-(0.61+0.03448636))/pf['his_pfarea'].loc[0]*100\n",
    "pf_sen_percent['3'].loc[0] = (pf['3'].loc[0] - pf['his_pfarea'].loc[0]) / (3-(0.61+0.03448636))/pf['his_pfarea'].loc[0]*100\n",
    "pf_sen_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c17599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
